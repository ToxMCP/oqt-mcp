"""
Integration utilities for reusing the original O-QT assistant multi-agent workflow
inside the MCP server.

The code in this module wraps the reusable pieces from the public O-QT assistant
repository so that, when available, the MCP workflow can produce the exact same
Markdown narrative, log bundle, and PDF artefact that the Streamlit app emits.

If the `oqt_assistant` package (and its dependencies) is not installed, the helper
gracefully reports that the assistant workflow is unavailable and callers can
fall back to the deterministic summary currently generated by the MCP.
"""

from __future__ import annotations

import asyncio
import base64
import hashlib
import json
import logging
import os
import time
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)

try:
    from oqt_assistant.utils.data_formatter import (
        process_experimental_metadata,
        process_qsar_predictions,
    )
    from oqt_assistant.utils.hit_selection import select_hit_with_properties
    from oqt_assistant.utils.llm_utils import (
        analyze_chemical_context,
        analyze_environmental_fate,
        analyze_experimental_data,
        analyze_metabolism,
        analyze_physical_properties,
        analyze_profiling_reactivity,
        analyze_qsar_predictions,
        analyze_read_across,
        synthesize_report,
    )
    from oqt_assistant.utils.pdf_generator import generate_pdf_report
    from oqt_assistant.utils.qprf_enrichment import QPRFEnricher
    from oqt_assistant.utils.qsar_api import (
        QSARResponseError,
        QSARToolboxAPI,
        SearchOptions,
    )
    from oqt_assistant.utils.qsar_models import (
        RECOMMENDED_QSAR_LIMIT,
        derive_recommended_qsar_models,
        run_qsar_predictions,
    )

    ASSISTANT_IMPORTED = True
except ImportError:  # pragma: no cover - executed when optional dependency missing
    ASSISTANT_IMPORTED = False


MAX_METABOLITES_PER_SIMULATOR = 50

MODEL_PRESETS = {
    "gpt-4.1": {"max_tokens": 10_000, "temperature": 0.10, "reasoning_effort": None},
    "gpt-4.1-mini": {
        "max_tokens": 10_000,
        "temperature": 0.10,
        "reasoning_effort": None,
    },
    "gpt-4.1-nano": {
        "max_tokens": 8_000,
        "temperature": 0.10,
        "reasoning_effort": None,
    },
}


@dataclass
class AssistantConfig:
    provider: str
    model: str
    api_key: str
    api_base: Optional[str]
    temperature: Optional[float]
    reasoning_effort: Optional[str]
    max_tokens: int


@dataclass
class AssistantResult:
    final_report: str
    specialist_sections: Dict[str, str]
    log_bundle: Dict[str, Any]
    pdf_bytes: bytes
    duration_s: float


def is_available() -> bool:
    """Returns True when the oqt_assistant modules are importable."""
    return ASSISTANT_IMPORTED


def _mask_key(value: str) -> str:
    if len(value) < 8:
        return "***"
    return f"{value[:4]}***MASKED***{value[-4:]}"


def resolve_assistant_config(
    *,
    provider_override: Optional[str],
    model_override: Optional[str],
    api_key_override: Optional[str],
    temperature_override: Optional[float] = None,
    reasoning_effort_override: Optional[str] = None,
) -> Optional[AssistantConfig]:
    """
    Derive the assistant configuration from explicit parameters or environment variables.

    Returns None when insufficient information (e.g., missing provider or API key).
    """
    if not is_available():
        return None

    provider = (
        provider_override
        or os.getenv("ASSISTANT_PROVIDER")
        or os.getenv("OQT_ASSISTANT_PROVIDER")
    )

    if not provider:
        return None

    provider = provider.strip()
    api_key = (
        api_key_override
        or os.getenv("ASSISTANT_API_KEY")
        or (os.getenv("OPENAI_API_KEY") if provider.lower() == "openai" else None)
        or (
            os.getenv("OPENROUTER_API_KEY")
            if provider.lower() == "openrouter"
            else None
        )
    )

    if not api_key:
        logger.warning(
            "Assistant provider '%s' requested but no API key found in parameters or environment.",
            provider,
        )
        return None

    model = (
        model_override
        or os.getenv("ASSISTANT_MODEL")
        or os.getenv("OQT_ASSISTANT_MODEL")
        or "gpt-4.1-nano"
    )

    preset = MODEL_PRESETS.get(model)
    max_tokens = preset["max_tokens"] if preset else 8_000
    temperature = (
        temperature_override
        if temperature_override is not None
        else os.getenv("ASSISTANT_TEMPERATURE")
        or os.getenv("OQT_ASSISTANT_TEMPERATURE")
    )

    if isinstance(temperature, str):
        try:
            temperature = float(temperature)
        except ValueError:
            logger.warning(
                "Invalid ASSISTANT_TEMPERATURE value '%s'; using preset default.",
                temperature,
            )
            temperature = preset["temperature"] if preset else 0.1

    if temperature is None:
        temperature = preset["temperature"] if preset else 0.1

    reasoning_effort = reasoning_effort_override or os.getenv(
        "ASSISTANT_REASONING_EFFORT"
    )
    api_base = os.getenv("ASSISTANT_API_BASE")

    if provider.lower() == "openrouter" and not api_base:
        api_base = "https://openrouter.ai/api/v1"

    logger.info(
        "Assistant enabled using provider=%s model=%s (key=%s).",
        provider,
        model,
        _mask_key(api_key),
    )
    return AssistantConfig(
        provider=provider,
        model=model,
        api_key=api_key,
        api_base=api_base,
        temperature=temperature,
        reasoning_effort=reasoning_effort,
        max_tokens=max_tokens,
    )


def _clear_agent_caches():
    """
    Prevent cached answers between runs. Mirrors the helper in batch_reports.py.
    """
    analyze_chemical_context.cache_clear()
    analyze_physical_properties.cache_clear()
    analyze_environmental_fate.cache_clear()
    analyze_profiling_reactivity.cache_clear()
    analyze_experimental_data.cache_clear()
    analyze_metabolism.cache_clear()
    analyze_qsar_predictions.cache_clear()
    analyze_read_across.cache_clear()
    synthesize_report.cache_clear()


def _build_llm_config(config: AssistantConfig) -> Dict[str, Any]:
    """
    Build the configuration dictionary expected by the oqt_assistant agent helpers.
    """
    model_id = config.model
    if config.provider.lower() == "openrouter" and config.model.startswith("gpt-"):
        model_id = f"openai/{config.model}"

    return {
        "provider": config.provider,
        "model_name": config.model,
        "model_id": model_id,
        "api_key": config.api_key,
        "api_base": config.api_base,
        "max_tokens": config.max_tokens,
        "reasoning_effort": config.reasoning_effort,
        "temperature": config.temperature,
        "temperature_override": None,
        "max_tokens_override": None,
    }


def _md5_bytes(data: bytes) -> str:
    digest = hashlib.md5()
    digest.update(data)
    return digest.hexdigest()


def _short_hash(text: str) -> str:
    digest = hashlib.sha256()
    digest.update(text.encode("utf-8", errors="ignore"))
    return digest.hexdigest()[:16]


def _build_log(
    *,
    identifier: str,
    context: str,
    llm_config: Dict[str, Any],
    qsar_url: str,
    results: Dict[str, Any],
    specialist: Dict[str, str],
    final_report: str,
    simulator_guids: List[str],
) -> Dict[str, Any]:
    """
    Assemble the comprehensive log bundle expected by the assistant PDF generator.
    """
    masked_key = llm_config.get("api_key") or ""
    if masked_key:
        masked_key = _mask_key(masked_key)

    timestamp = time.time()
    log = {
        "identifier": identifier,
        "context": context,
        "timestamp": timestamp,
        "hash": _short_hash(f"{identifier}:{timestamp}"),
        "llm_config": {
            "provider": llm_config.get("provider"),
            "model": llm_config.get("model_name"),
            "api_base": llm_config.get("api_base"),
            "masked_api_key": masked_key,
            "temperature": llm_config.get("temperature"),
            "max_tokens": llm_config.get("max_tokens"),
            "reasoning_effort": llm_config.get("reasoning_effort"),
        },
        "qsar_toolbox": {
            "base_url": qsar_url,
            "simulator_guids_used": simulator_guids,
        },
        "data_retrieval": {
            "processed_qsar_toolbox_data": results,
        },
        "analysis": {
            "specialist_agent_outputs": specialist,
            "synthesized_report": final_report,
        },
    }
    return log


async def _run_agents(
    bundle: Dict[str, Any],
    *,
    identifier: str,
    context: str,
    llm_config: Dict[str, Any],
) -> Tuple[str, Dict[str, str]]:
    """
    Execute the oqt_assistant specialist agents and synthesiser.
    """
    specialist_outputs: Dict[str, str] = {}
    logger.info("  [Analysis] Starting assistant agents.")

    try:
        identity_txt = await analyze_chemical_context(
            {"basic_info": bundle.get("chemical_data", {}).get("basic_info", {})},
            context,
            llm_config,
        )
    except Exception as exc:  # pragma: no cover - defensive branch
        logger.error("Chemical context agent failed: %s", exc)
        identity_txt = f"[Chemical Context agent failed: {exc}]"

    specialist_outputs["Chemical_Context"] = identity_txt
    analysis_context = f"{identity_txt}\n\nUser Goal: {context}"

    props = bundle.get("chemical_data", {}).get("properties", {})
    profiling = bundle.get("profiling", {})
    metabolism = bundle.get("metabolism", {})
    exp_list = bundle.get("experimental_data", [])
    exp_payload = {"experimental_results": exp_list}
    qsar_processed = bundle.get("qsar_models", {}).get("processed", {})

    tasks = [
        asyncio.create_task(
            analyze_physical_properties(props, analysis_context, llm_config)
        ),
        asyncio.create_task(
            analyze_environmental_fate(props, analysis_context, llm_config)
        ),
        asyncio.create_task(
            analyze_profiling_reactivity(profiling, analysis_context, llm_config)
        ),
        asyncio.create_task(
            analyze_experimental_data(exp_payload, analysis_context, llm_config)
        ),
        asyncio.create_task(
            analyze_metabolism(metabolism, analysis_context, llm_config)
        ),
        asyncio.create_task(
            analyze_qsar_predictions(qsar_processed, analysis_context, llm_config)
        ),
    ]
    labels = [
        "Physical_Properties",
        "Environmental_Fate",
        "Profiling_Reactivity",
        "Experimental_Data",
        "Metabolism",
        "QSAR_Predictions",
    ]

    core_outputs: List[str] = []
    results = await asyncio.gather(*tasks, return_exceptions=True)
    for label, result in zip(labels, results):
        if isinstance(result, Exception):
            logger.error("%s agent failed: %s", label, result)
            fallback = f"[{label} agent failed: {result}]"
            core_outputs.append(fallback)
            specialist_outputs[label] = fallback
        else:
            text = str(result)
            core_outputs.append(text)
            specialist_outputs[label] = text

    try:
        read_across = await analyze_read_across(
            {"scope_config": {}, "experimental_data": exp_list, **bundle},
            core_outputs,
            analysis_context,
            llm_config,
        )
    except Exception as exc:  # pragma: no cover - defensive branch
        logger.error("Read-Across agent failed: %s", exc)
        read_across = f"[Read Across agent failed: {exc}]"

    specialist_outputs["Read_Across"] = read_across

    try:
        final_report = await synthesize_report(
            identifier, core_outputs, read_across, context, llm_config
        )
    except Exception as exc:  # pragma: no cover - defensive branch
        logger.error("Report synthesis failed: %s", exc)
        final_report = (
            "## ⚠️ Report Synthesis Fallback\n"
            f"**Reason:** Synthesis failed ({exc})\n\n"
            "Below is a concatenation of specialist outputs:\n\n"
            "### Specialist Outputs\n" + "\n\n---\n\n".join(core_outputs) + "\n\n"
            "### Read-Across\n" + read_across
        )

    return final_report, specialist_outputs


def _normalise_simulator_catalog(
    simulators: List[Dict[str, Any]]
) -> List[Tuple[str, str]]:
    normalised = []
    for entry in simulators or []:
        guid = entry.get("Guid") or entry.get("GUID") or entry.get("guid")
        name = (
            entry.get("Name")
            or entry.get("Caption")
            or entry.get("label")
            or (guid[:8] if guid else "Unknown simulator")
        )
        if guid:
            normalised.append((name, guid))
    return normalised


def _filter_simulators(
    available: List[Tuple[str, str]],
    requested_guids: Optional[List[str]],
) -> List[Tuple[str, str]]:
    if not requested_guids:
        return available
    requested_lower = {guid.lower() for guid in requested_guids}
    filtered = [
        (name, guid) for name, guid in available if guid.lower() in requested_lower
    ]
    return filtered


def _filter_qsar_models(
    catalog_snapshot: List[Dict[str, Any]],
    exclude_guids: Optional[List[str]],
    exclude_contains: Optional[List[str]],
) -> List[Dict[str, Any]]:
    if not catalog_snapshot:
        return []
    guid_filter = {g.lower() for g in exclude_guids or [] if isinstance(g, str)}
    substrings = tuple(s.lower() for s in exclude_contains or [] if isinstance(s, str))
    filtered = []
    for entry in catalog_snapshot:
        guid_lower = str(entry.get("Guid") or "").lower()
        if guid_filter and guid_lower in guid_filter:
            continue
        caption_lower = (entry.get("Caption") or "").lower()
        position_lower = (
            entry.get("RequestedPosition") or entry.get("Position") or ""
        ).lower()
        if substrings and any(
            sub in caption_lower or sub in position_lower for sub in substrings
        ):
            continue
        filtered.append(entry)
    return filtered


def _fetch_qsar_bundle(
    api: QSARToolboxAPI,
    identifier: str,
    search_type: str,
    *,
    enable_metabolism: bool,
    simulator_guids: Optional[List[str]],
    include_qsar: bool,
    selected_qsar_guids: Optional[List[str]],
    fast_qsar: bool,
    qsar_limit: Optional[int],
    context_str: str,
    exclude_qsar_guids: Optional[List[str]],
    exclude_qsar_contains: Optional[List[str]],
    qsar_model_timeout_s: Optional[int],
    qsar_total_budget_s: Optional[int],
) -> Tuple[Dict[str, Any], str, str, List[str]]:
    normalised_search = (search_type or "auto").strip().lower()
    logger.info(
        "  [Data Fetch] Searching Toolbox for '%s' (mode=%s)",
        identifier,
        normalised_search,
    )

    hits: List[Dict[str, Any]] = []
    search_attempts: List[str] = []

    if normalised_search in {"auto", "name"}:
        search_attempts.append("name-exact")
        hits = api.search_by_name(identifier, search_option=SearchOptions.EXACT_MATCH)
        if not hits:
            search_attempts.append("name-contains")
            hits = api.search_by_name(identifier, search_option=SearchOptions.CONTAINS)

    if not hits and normalised_search in {"auto", "cas"}:
        try:
            search_attempts.append("cas")
            hits = api.search_by_cas(identifier)
        except Exception as exc:
            logger.debug("CAS search failed for %s: %s", identifier, exc)

    if not hits and normalised_search in {"auto", "smiles"}:
        try:
            search_attempts.append("smiles")
            hits = api.search_by_smiles(identifier)
        except Exception as exc:
            logger.debug("SMILES search failed for %s: %s", identifier, exc)

    logger.debug("Search attempts performed: %s", ", ".join(search_attempts))

    if not hits:
        raise RuntimeError(f"No Toolbox structures matched '{identifier}'.")

    selected_basic, props, chem_id, _notes = select_hit_with_properties(
        api, identifier, hits, logger=logger
    )

    metabolism_data: Dict[str, Any] = {
        "status": "Skipped",
        "simulations": {},
        "available_simulators": [],
    }
    simulator_guids_used: List[str] = []

    if enable_metabolism:
        try:
            catalog = _normalise_simulator_catalog(api.get_simulators() or [])
        except Exception as exc:
            catalog = []
            logger.warning("Could not list metabolism simulators: %s", exc)

        metabolism_data["available_simulators"] = [
            {"name": name, "guid": guid} for name, guid in catalog
        ]
        to_run = _filter_simulators(catalog, simulator_guids)

        if not to_run:
            metabolism_data["status"] = "Skipped"
            metabolism_data["note"] = (
                "Metabolism enabled but no matching simulators available."
            )
        else:
            logger.info("  [Data Fetch] Running %d metabolism simulators.", len(to_run))
            completed = 0
            for index, (name, guid) in enumerate(to_run, start=1):
                simulation_result = {
                    "status": "Pending",
                    "simulator_name": name,
                    "simulator_guid": guid,
                    "metabolites": [],
                }
                try:
                    raw_metabolites = api.apply_simulator(guid, chem_id) or []
                    metabolites = raw_metabolites[:MAX_METABOLITES_PER_SIMULATOR]
                    note = f"Generated {len(raw_metabolites)} metabolites"
                    if len(raw_metabolites) > len(metabolites):
                        note += f" (truncated to {MAX_METABOLITES_PER_SIMULATOR})."
                    simulation_result["status"] = "Success"
                    simulation_result["note"] = note
                    simulation_result["metabolites"] = metabolites
                    completed += 1
                    simulator_guids_used.append(guid)
                except QSARResponseError as exc:
                    logger.warning("Metabolism simulator %s failed: %s", name, exc)
                    simulation_result["status"] = "Failed"
                    simulation_result["note"] = str(exc)
                metabolism_data["simulations"][guid] = simulation_result

            total = len(to_run)
            if completed == 0:
                metabolism_data["status"] = "Failed"
            elif completed == total:
                metabolism_data["status"] = "Success"
            else:
                metabolism_data["status"] = "Partial Success"
            metabolism_data["note"] = f"{completed}/{total} simulators completed."
    else:
        metabolism_data["status"] = "Skipped"
        metabolism_data["note"] = "Metabolism simulation disabled."

    logger.info(
        "  [Data Fetch] Retrieving experimental data and profiling information."
    )
    enrichment = {}
    try:
        enricher = QPRFEnricher(api)
        selected_basic = enricher.enrich_substance_identity(selected_basic)
        if props:
            props = enricher.enrich_calculator_results(props)
        enrichment = enricher.get_software_info()
    except Exception as exc:
        logger.warning("QPRF enrichment failed (non critical): %s", exc)

    experimental = process_experimental_metadata(
        api.get_all_chemical_data(chem_id, include_metadata=True) or []
    )
    profiling = api.get_chemical_profiling(chem_id) or {}

    raw_qsar = {
        "catalog_size": 0,
        "executed_models": 0,
        "predictions": [],
        "summary": {"total": 0},
    }
    qsar_processed = process_qsar_predictions([])

    if include_qsar:
        logger.info("  [Data Fetch] Running QSAR models.")
        try:
            preset_guids: Optional[List[str]] = None
            if selected_qsar_guids:
                preset_guids = selected_qsar_guids
            elif fast_qsar or (qsar_limit and qsar_limit > 0):
                snapshot = api.get_all_qsar_models_catalog() or []
                snapshot = _filter_qsar_models(
                    snapshot, exclude_qsar_guids, exclude_qsar_contains
                )
                limit = (
                    qsar_limit
                    if (qsar_limit and qsar_limit > 0)
                    else RECOMMENDED_QSAR_LIMIT
                )
                recommended = derive_recommended_qsar_models(snapshot, limit=limit)
                preset_guids = [
                    entry.get("Guid") for entry in recommended if entry.get("Guid")
                ]
                logger.info(
                    "  [QSAR] Using recommended preset of %d models.",
                    len(preset_guids or []),
                )

            raw_qsar = run_qsar_predictions(
                api,
                chem_id,
                selected_model_guids=preset_guids,
                max_models=qsar_limit if (qsar_limit and qsar_limit > 0) else None,
                exclude_guids=exclude_qsar_guids,
                exclude_contains=exclude_qsar_contains,
                per_model_timeout_s=qsar_model_timeout_s,
                total_budget_s=qsar_total_budget_s,
                logger=logger,
            )
            qsar_processed = process_qsar_predictions(raw_qsar.get("predictions", []))
        except Exception as exc:
            logger.error("QSAR model execution failed: %s", exc)

    bundle = {
        "chemical_data": {"basic_info": selected_basic, "properties": props},
        "experimental_data": experimental,
        "profiling": profiling,
        "metabolism": metabolism_data,
        "qsar_models": {"raw": raw_qsar, "processed": qsar_processed},
        "context": context_str,
        "_internal_meta": {"simulator_guids_used": simulator_guids_used},
        "qprf_metadata": {
            "software": enrichment,
            "enrichment_applied": bool(enrichment),
        },
    }
    return (
        bundle,
        chem_id,
        selected_basic.get("SubstanceName") or identifier,
        simulator_guids_used,
    )


async def generate_assistant_output(
    *,
    identifier: str,
    search_type: str,
    context: str,
    qsar_base_url: str,
    config: AssistantConfig,
    simulator_guids: Optional[List[str]],
    include_qsar: bool,
    selected_qsar_guids: Optional[List[str]],
    fast_qsar: bool,
    qsar_limit: Optional[int],
    exclude_qsar_guids: Optional[List[str]] = None,
    exclude_qsar_contains: Optional[List[str]] = None,
    qsar_model_timeout_s: Optional[int] = None,
    qsar_total_budget_s: Optional[int] = None,
    enable_metabolism: bool = False,
) -> AssistantResult:
    """
    Runs the full oqt_assistant data collection + LLM pipeline and returns the artefacts.
    """
    if not is_available():
        raise RuntimeError(
            "oqt_assistant is not installed; assistant workflow unavailable."
        )

    start = time.time()
    api = QSARToolboxAPI(base_url=qsar_base_url)

    bundle, chem_id, preferred_name, simulator_guids_used = _fetch_qsar_bundle(
        api,
        identifier,
        search_type,
        enable_metabolism=enable_metabolism,
        simulator_guids=simulator_guids,
        include_qsar=include_qsar,
        selected_qsar_guids=selected_qsar_guids,
        fast_qsar=fast_qsar,
        qsar_limit=qsar_limit,
        context_str=context,
        exclude_qsar_guids=exclude_qsar_guids,
        exclude_qsar_contains=exclude_qsar_contains,
        qsar_model_timeout_s=qsar_model_timeout_s,
        qsar_total_budget_s=qsar_total_budget_s,
    )

    llm_cfg = _build_llm_config(config)
    _clear_agent_caches()

    final_report, specialist_outputs = await _run_agents(
        bundle,
        identifier=preferred_name or chem_id or identifier,
        context=bundle["context"],
        llm_config=llm_cfg,
    )
    log_bundle = _build_log(
        identifier=preferred_name or identifier,
        context=bundle["context"],
        llm_config=llm_cfg,
        qsar_url=qsar_base_url,
        results=bundle,
        specialist=specialist_outputs,
        final_report=final_report,
        simulator_guids=simulator_guids_used,
    )

    try:
        pdf_io = generate_pdf_report(log_bundle)
        pdf_bytes = pdf_io.getvalue()
    except Exception as exc:  # pragma: no cover - defensive branch
        logger.error("Assistant PDF generation failed: %s", exc)
        pdf_bytes = b""

    duration = time.time() - start
    return AssistantResult(
        final_report=final_report,
        specialist_sections=specialist_outputs,
        log_bundle=log_bundle,
        pdf_bytes=pdf_bytes,
        duration_s=duration,
    )


def encode_pdf(pdf_bytes: bytes) -> Dict[str, Any]:
    """
    Helper to wrap PDF bytes in the standard MCP artifact envelope.
    """
    encoded = base64.b64encode(pdf_bytes or b"").decode("utf-8")
    return {
        "base64": encoded,
        "size_bytes": len(pdf_bytes or b""),
        "md5": _md5_bytes(pdf_bytes or b""),
    }
